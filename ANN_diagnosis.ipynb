{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "564  926424         M        21.56         22.39          142.00     1479.0   \n",
       "565  926682         M        20.13         28.25          131.20     1261.0   \n",
       "566  926954         M        16.60         28.08          108.30      858.1   \n",
       "567  927241         M        20.60         29.33          140.10     1265.0   \n",
       "568   92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division independant features and target and replace M to 1 ,B to 0\n",
    "X = df.iloc[:, 2:32]\n",
    "y = df.iloc[:, 1].replace({'M': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "564    1\n",
       "565    1\n",
       "566    1\n",
       "567    1\n",
       "568    0\n",
       "Name: diagnosis, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train/test\n",
    "#y = y.values \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4626 - loss: 0.6658\n",
      "Epoch 2/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.5738\n",
      "Epoch 3/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.5071\n",
      "Epoch 4/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.3415\n",
      "Epoch 5/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2762\n",
      "Epoch 6/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.2307\n",
      "Epoch 7/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.2634\n",
      "Epoch 8/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2310\n",
      "Epoch 9/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.2235\n",
      "Epoch 10/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.2311\n",
      "Epoch 11/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2348\n",
      "Epoch 12/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2309\n",
      "Epoch 13/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.1920\n",
      "Epoch 14/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.2681\n",
      "Epoch 15/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.1956\n",
      "Epoch 16/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2232\n",
      "Epoch 17/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.3040\n",
      "Epoch 18/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2345\n",
      "Epoch 19/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.1918\n",
      "Epoch 20/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2094\n",
      "Epoch 21/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2225\n",
      "Epoch 22/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2210\n",
      "Epoch 23/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.1790\n",
      "Epoch 24/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.2391\n",
      "Epoch 25/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9284 - loss: 0.1752\n",
      "Epoch 26/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.1944\n",
      "Epoch 27/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.1626\n",
      "Epoch 28/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8731 - loss: 0.2969\n",
      "Epoch 29/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9370 - loss: 0.2056\n",
      "Epoch 30/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9397 - loss: 0.1831\n",
      "Epoch 31/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.1801\n",
      "Epoch 32/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1694\n",
      "Epoch 33/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.1766\n",
      "Epoch 34/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.1760\n",
      "Epoch 35/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.1816\n",
      "Epoch 36/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9111 - loss: 0.2247\n",
      "Epoch 37/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9407 - loss: 0.1556\n",
      "Epoch 38/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9337 - loss: 0.1858\n",
      "Epoch 39/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.1921\n",
      "Epoch 40/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.2257\n",
      "Epoch 41/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1741\n",
      "Epoch 42/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.1960\n",
      "Epoch 43/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2088\n",
      "Epoch 44/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.1576\n",
      "Epoch 45/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.1584\n",
      "Epoch 46/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.1837\n",
      "Epoch 47/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.1873\n",
      "Epoch 48/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.2004\n",
      "Epoch 49/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.1823\n",
      "Epoch 50/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.1493\n",
      "Epoch 51/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1605\n",
      "Epoch 52/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9391 - loss: 0.1587\n",
      "Epoch 53/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.1896\n",
      "Epoch 54/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.1899\n",
      "Epoch 55/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9405 - loss: 0.1557\n",
      "Epoch 56/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.1613\n",
      "Epoch 57/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.1982\n",
      "Epoch 58/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.1899\n",
      "Epoch 59/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1449\n",
      "Epoch 60/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.1941\n",
      "Epoch 61/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.2943\n",
      "Epoch 62/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9292 - loss: 0.1635\n",
      "Epoch 63/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1755\n",
      "Epoch 64/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.1979\n",
      "Epoch 65/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.1668\n",
      "Epoch 66/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.1639\n",
      "Epoch 67/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9228 - loss: 0.1712\n",
      "Epoch 68/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.1808\n",
      "Epoch 69/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.1835\n",
      "Epoch 70/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.1726\n",
      "Epoch 71/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.1853\n",
      "Epoch 72/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9328 - loss: 0.1570\n",
      "Epoch 73/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9241 - loss: 0.1624\n",
      "Epoch 74/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.1629\n",
      "Epoch 75/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1768\n",
      "Epoch 76/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.1784\n",
      "Epoch 77/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.1927\n",
      "Epoch 78/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.1945\n",
      "Epoch 79/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.1914\n",
      "Epoch 80/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2043\n",
      "Epoch 81/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.1512\n",
      "Epoch 82/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.1608\n",
      "Epoch 83/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1617\n",
      "Epoch 84/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1466\n",
      "Epoch 85/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.1560\n",
      "Epoch 86/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9354 - loss: 0.1376\n",
      "Epoch 87/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.1671\n",
      "Epoch 88/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.1667\n",
      "Epoch 89/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1090\n",
      "Epoch 90/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.1719\n",
      "Epoch 91/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.1662\n",
      "Epoch 92/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1533\n",
      "Epoch 93/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.1274\n",
      "Epoch 94/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.1825\n",
      "Epoch 95/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.1683\n",
      "Epoch 96/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9572 - loss: 0.1245\n",
      "Epoch 97/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.1259\n",
      "Epoch 98/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2171\n",
      "Epoch 99/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1246\n",
      "Epoch 100/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.1511\n",
      "Epoch 1/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1693\n",
      "Epoch 2/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1261\n",
      "Epoch 3/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.1451\n",
      "Epoch 4/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9306 - loss: 0.1294\n",
      "Epoch 5/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1293\n",
      "Epoch 6/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.1383\n",
      "Epoch 7/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1298\n",
      "Epoch 8/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1145\n",
      "Epoch 9/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.1096\n",
      "Epoch 10/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.1468\n",
      "Epoch 11/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.1156\n",
      "Epoch 12/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.1544\n",
      "Epoch 13/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.1539\n",
      "Epoch 14/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.1856\n",
      "Epoch 15/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.1304\n",
      "Epoch 16/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1057\n",
      "Epoch 17/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1110\n",
      "Epoch 18/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1161\n",
      "Epoch 19/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.1324\n",
      "Epoch 20/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8970 - loss: 0.2139\n",
      "Epoch 21/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9357 - loss: 0.1394\n",
      "Epoch 22/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.1237\n",
      "Epoch 23/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1355\n",
      "Epoch 24/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1280\n",
      "Epoch 25/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.1531\n",
      "Epoch 26/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1324\n",
      "Epoch 27/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.1487\n",
      "Epoch 28/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1429\n",
      "Epoch 29/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.1065\n",
      "Epoch 30/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.1453\n",
      "Epoch 31/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.1608\n",
      "Epoch 32/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9525 - loss: 0.1198\n",
      "Epoch 33/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1364\n",
      "Epoch 34/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9345 - loss: 0.1498\n",
      "Epoch 35/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9574 - loss: 0.1376\n",
      "Epoch 36/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.1540\n",
      "Epoch 37/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.1528\n",
      "Epoch 38/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1305\n",
      "Epoch 39/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9524 - loss: 0.1128\n",
      "Epoch 40/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1035\n",
      "Epoch 41/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1237\n",
      "Epoch 42/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.1779\n",
      "Epoch 43/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.1312\n",
      "Epoch 44/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1064\n",
      "Epoch 45/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1136\n",
      "Epoch 46/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.1374\n",
      "Epoch 47/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.1603\n",
      "Epoch 48/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.1335\n",
      "Epoch 49/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1231\n",
      "Epoch 50/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.1631\n",
      "Epoch 51/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.1261\n",
      "Epoch 52/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.1457\n",
      "Epoch 53/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1073\n",
      "Epoch 54/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.1276\n",
      "Epoch 55/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.0978\n",
      "Epoch 56/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.2348\n",
      "Epoch 57/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.1540\n",
      "Epoch 58/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.0930\n",
      "Epoch 59/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9306 - loss: 0.1594\n",
      "Epoch 60/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9445 - loss: 0.1207\n",
      "Epoch 61/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.1237\n",
      "Epoch 62/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9381 - loss: 0.1386\n",
      "Epoch 63/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.1375\n",
      "Epoch 64/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9343 - loss: 0.1358\n",
      "Epoch 65/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1506\n",
      "Epoch 66/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.1281\n",
      "Epoch 67/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9556 - loss: 0.1294\n",
      "Epoch 68/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9403 - loss: 0.1148\n",
      "Epoch 69/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1175\n",
      "Epoch 70/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1016\n",
      "Epoch 71/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.0899\n",
      "Epoch 72/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1130\n",
      "Epoch 73/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1145\n",
      "Epoch 74/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1048\n",
      "Epoch 75/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1017\n",
      "Epoch 76/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.1219\n",
      "Epoch 77/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.1636\n",
      "Epoch 78/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.1462\n",
      "Epoch 79/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.0971\n",
      "Epoch 80/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.1575\n",
      "Epoch 81/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.1406\n",
      "Epoch 82/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1206\n",
      "Epoch 83/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1225\n",
      "Epoch 84/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.1516\n",
      "Epoch 85/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9360 - loss: 0.1144\n",
      "Epoch 86/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.1319\n",
      "Epoch 87/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1343\n",
      "Epoch 88/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1388\n",
      "Epoch 89/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.1389\n",
      "Epoch 90/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1152\n",
      "Epoch 91/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.1282\n",
      "Epoch 92/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.1356\n",
      "Epoch 93/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.1130\n",
      "Epoch 94/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.0979\n",
      "Epoch 95/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9543 - loss: 0.1084\n",
      "Epoch 96/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.1671\n",
      "Epoch 97/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.1787\n",
      "Epoch 98/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1178\n",
      "Epoch 99/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1422\n",
      "Epoch 100/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.1440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24e401f3be0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "# adding the input layer and the first hidden layer\n",
    "\n",
    "# Il n'existe pas de règles standard pour déterminer le nombre de neurones \n",
    "# la couche cachée mais une astuce est de prendre la moitié de la somme des \n",
    "# neurones d'entrée et de sortie d'ou 6 ici.\n",
    "# La méthode .add()permet d'ajouter une couche cachée mais la première fois qu'on\n",
    "# crée une couche cachée, il faut définir la couche d'entrée car elle est créée automatiquement\n",
    "\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu', input_dim = 30))\n",
    "\n",
    "# Adding the second hidden layer \n",
    "# Ajouter une deuxième couche cachée (Pas toujours nécessaire mais raison pédagogique)\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Ajouter la couche de sortie\n",
    "# On a une seule variable de sortie donc un seul neurone et on choisit 1 ou 0 donc la fonction sigmoide\n",
    "# comme fonction d'activation. Si c'était une classif multiclasse, on choisirait 'softmax' comme fonction\n",
    "# et on aurait 3 neurones de sorties\"\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "# Si l'on avait plus de 2 catégories à prédire, la loss function serait 'categorical_crossentropy\n",
    "# 'adam' est la version du gradient stochastique utilisée pour mettre à jour les poids\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Entrainer le réseau de neurones\n",
    "# batch_size: nombre de lignes à faire passer en meme temps dans le réseau de neurones\n",
    "# epochs: nombre d'itérations\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n",
    "\n",
    "# Entrainer le réseau de neurones\n",
    "# batch_size: nombre de lignes à faire passer en meme temps dans le réseau de neurones\n",
    "# epochs: nombre d'itérations\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[y_pred>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
     ]
    }
   ],
   "source": [
    "# Faire des prédiction avec le réseau de neurones entrainé\n",
    "# Exercice: Prédire un seule prédiction\n",
    "\"\"\"To predict whether a given tumor is benign (B) or malignant (M).:\n",
    "\"\"\"\n",
    "\n",
    "Xnew = pd.DataFrame(data={\n",
    "        \"radius_mean\" : [17.99], \n",
    "        \"texture_mean\": [10.38], \n",
    "        \"perimeter_mean\": [122.8], \n",
    "        \"area_mean\": [1001], \n",
    "        \"smoothness_mean\": [0.1184], \n",
    "        \"compactness_mean\": [0.2776], \n",
    "        \"concavity_mean\": [0.3001], \n",
    "        \"concave points_mean\": [0.1471], \n",
    "        \"symmetry_mean\": [0.2419], \n",
    "        \"fractal_dimension_mean\": [0.07871], \n",
    "        \"radius_se\": [1.095], \n",
    "        \"texture_se\": [0.9053], \n",
    "        \"perimeter_se\": [8.589], \n",
    "        \"area_se\": [153.4], \n",
    "        \"smoothness_se\": [0.006399], \n",
    "        \"compactness_se\": [0.04904], \n",
    "        \"concavity_se\": [0.05373], \n",
    "        \"concave points_se\": [0.01587], \n",
    "        \"symmetry_se\": [0.03003], \n",
    "        \"fractal_dimension_se\": [0.006193], \n",
    "        \"radius_worst\": [25.38], \n",
    "        \"texture_worst\": [17.33], \n",
    "        \"perimeter_worst\": [184.6], \n",
    "        \"area_worst\": [2019], \n",
    "        \"smoothness_worst\": [0.1622], \n",
    "        \"compactness_worst\": [0.6656], \n",
    "        \"concavity_worst\": [0.7119], \n",
    "        \"concave points_worst\": [0.2654], \n",
    "        \"symmetry_worst\": [0.4601], \n",
    "        \"fractal_dimension_worst\": [0.1189], \n",
    "})\n",
    "\n",
    "new_prediction = classifier.predict(Xnew)\n",
    "new_prediction = (new_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# La matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=[8,5])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63  4]\n",
      " [ 2 45]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
